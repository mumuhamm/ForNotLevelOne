{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nflows\n",
      "  Downloading nflows-0.14.tar.gz (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib64/python3.9/site-packages (from nflows) (3.4.3)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.9/site-packages (from nflows) (1.20.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/site-packages (from nflows) (2.7.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 755.5 MB 57 kB/s s eta 0:00:012    |████████████                    | 285.8 MB 25.2 MB/s eta 0:00:19     |██████████████████████▌         | 531.8 MB 9.0 MB/s eta 0:00:25     |███████████████████████████████ | 732.1 MB 16.5 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from nflows) (4.62.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.9/site-packages (from matplotlib->nflows) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib64/python3.9/site-packages (from matplotlib->nflows) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib64/python3.9/site-packages (from matplotlib->nflows) (8.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.9/site-packages (from matplotlib->nflows) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3.9/site-packages (from matplotlib->nflows) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->nflows) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (1.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (0.37.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3.9/site-packages (from tensorboard->nflows) (53.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib64/python3.9/site-packages (from tensorboard->nflows) (1.42.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3.9/site-packages (from tensorboard->nflows) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib64/python3.9/site-packages (from tensorboard->nflows) (3.19.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard->nflows) (3.3.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->nflows) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->nflows) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->nflows) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->nflows) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->nflows) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->nflows) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->nflows) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->nflows) (1.25.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard->nflows) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (3.1.1)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 3.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 32.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 25.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 41.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==2.2.0\n",
      "  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 167.9 MB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 23.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 731.7 MB 43 kB/s s eta 0:00:01    |███                             | 69.5 MB 23.5 MB/s eta 0:00:29     |██████████████████████████▉     | 613.0 MB 16.7 MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.9/site-packages (from torch->nflows) (2.11.3)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 18 kB/s s eta 0:00:01     |███████████████████████████▉    | 356.5 MB 23.0 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.0 MB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.9/site-packages (from torch->nflows) (2021.10.1)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.1 MB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/lib64/python3.9/site-packages (from jinja2->torch->nflows) (1.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 31.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nflows\n",
      "  Building wheel for nflows (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53671 sha256=aaa8524a69456da4e2fe574d06e4abe6fb9e36dc58046fc7bda8c06043dea698\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3b/88/52/cbd4ed0597b48916de3de19b28d7297c72595f56085068c772\n",
      "Successfully built nflows\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, filelock, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, networkx, torch, nflows\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed filelock-3.13.4 mpmath-1.3.0 networkx-3.2.1 nflows-0.14 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.2.2 triton-2.2.0 typing-extensions-4.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2, expon, weibull_min\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import nflows\n",
    "from nflows import flows, transforms\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import ConditionalDiagonalNormal\n",
    "from nflows.distributions.base import Distribution\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.nn.nets import ResidualNet\n",
    "from nflows.utils import torchutils\n",
    "\n",
    "np.random.seed(100)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available, using CPU instead.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    # Get current CUDA device index\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"Current CUDA Device index:\", current_device)\n",
    "    # Get name of the current CUDA device\n",
    "    print(\"Current CUDA Device:\", torch.cuda.get_device_name(current_device))\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        context_variables,\n",
    "        target_variables,\n",
    "        device=None,\n",
    "        rows=None,\n",
    "    ):\n",
    "        self.context_variables = context_variables\n",
    "        self.target_variables = target_variables\n",
    "        self.all_variables = context_variables + target_variables\n",
    "        data = dataframe\n",
    "        if rows is not None:\n",
    "            data = data.iloc[:rows]\n",
    "        self.target = data[target_variables].values\n",
    "        self.context = data[context_variables].values\n",
    "        self.weights = data[['weight']].values\n",
    "        if device is not None:\n",
    "            self.target = torch.tensor(self.target, dtype=torch.float32).to(device)\n",
    "            self.context = torch.tensor(self.context, dtype=torch.float32).to(device)\n",
    "            self.weights = torch.tensor(self.weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.context) == len(self.target)\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.context[idx], self.target[idx], self.weights[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400000 600000\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./flowsSample\"\n",
    "df = pd.read_parquet(os.path.join(input_dir, \"train.parquet\"))\n",
    "df_target = pd.read_parquet(os.path.join(input_dir, \"train_target.parquet\"))\n",
    "df_test = pd.read_parquet(os.path.join(input_dir, \"test.parquet\"))\n",
    "df_target_test = pd.read_parquet(os.path.join(input_dir, \"test_target.parquet\"))\n",
    "\n",
    "context_vars = ['a', 'b']\n",
    "input_vars = ['x', 'y']\n",
    "rows = 100000\n",
    "rows_test = 100000\n",
    "batch_size = 1000\n",
    "print(len(df), len(df_test))\n",
    "mc_dataset_train = MyDataset(df, context_vars, input_vars, device=device, rows=rows)\n",
    "mc_loader_train = DataLoader(mc_dataset_train, batch_size=batch_size)\n",
    "data_dataset_train = MyDataset(df_target, context_vars, input_vars, device=device, rows=rows)\n",
    "data_loader_train = DataLoader(data_dataset_train, batch_size=batch_size)\n",
    "mc_dataset_test = MyDataset(df_test, context_vars, input_vars, device=device, rows=rows_test)\n",
    "mc_loader_test = DataLoader(mc_dataset_test, batch_size=batch_size)\n",
    "data_dataset_test = MyDataset(df_target_test, context_vars, input_vars, device=device, rows=rows_test)\n",
    "data_loader_test = DataLoader(data_dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_dataset_train.context.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        if epoch % plot_every == 0:\\n            print(\"plotting\")\\n            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\\n            a, b, x, y = df_test[\\'a\\'].values, df_test[\\'b\\'].values, df_test[\\'x\\'].values, df_test[\\'y\\'].values\\n            xy_sample = flow.sample(1, context=torch.tensor(df_test[[\\'a\\', \\'b\\']].values, dtype=torch.float32).to(device)).reshape(-1, ninput)\\n            x_sample = xy_sample[:, 0].detach().cpu().numpy()\\n            y_sample = xy_sample[:, 1].detach().cpu().numpy()\\n            x_min = min(x.min(), x_sample.min())\\n            x_max = max(x.max(), x_sample.max())\\n            ax1.hist(x, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label=\\'sample\\');\\n            ax1.hist(x_sample, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label=\\'flow\\');\\n            y_min = min(y.min(), y_sample.min())\\n            y_max = max(y.max(), y_sample.max())\\n            ax1.legend()\\n            ax2.hist(y, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label=\\'sample\\');\\n            ax2.hist(y_sample, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label=\\'flow\\');\\n            ax2.legend()\\n            # plot loss\\n            ax3.plot(train_history, label=\\'train\\')\\n            ax3.plot(test_history, label=\\'test\\')\\n            ax3.legend()\\n            plt.show()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninput = len(input_vars)\n",
    "ncontext = len(context_vars)\n",
    "\n",
    "epochs = 20\n",
    "plot_every = 5\n",
    "\n",
    "class DiagonalGaussian(Distribution):\n",
    "    \"\"\"A diagonal multivariate Normal with trainable parameters.\"\"\"\n",
    "\n",
    "    def __init__(self, shape, mean, std):\n",
    "        \"\"\"Constructor.\n",
    "\n",
    "        Args:\n",
    "            shape: list, tuple or torch.Size, the shape of the input variables.\n",
    "            context_encoder: callable or None, encodes the context to the distribution parameters.\n",
    "                If None, defaults to the identity function.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._shape = torch.Size(shape)\n",
    "        self.mean_ = nn.Parameter(mean * torch.ones(shape).reshape(1, -1))\n",
    "        self.log_std_ = nn.Parameter(np.log(std) * torch.ones(shape).reshape(1, -1))\n",
    "        self.register_buffer(\"_log_z\",\n",
    "                             torch.tensor(0.5 * np.prod(shape) * np.log(2 * np.pi),\n",
    "                                          dtype=torch.float32),\n",
    "                             persistent=False)\n",
    "\n",
    "    def _log_prob(self, inputs, context):\n",
    "        if inputs.shape[1:] != self._shape:\n",
    "            raise ValueError(\n",
    "                \"Expected input of shape {}, got {}\".format(\n",
    "                    self._shape, inputs.shape[1:]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Compute parameters.\n",
    "        means = self.mean_\n",
    "        log_stds = self.log_std_\n",
    "\n",
    "        # Compute log prob.\n",
    "        norm_inputs = (inputs - means) * torch.exp(-log_stds)\n",
    "        log_prob = -0.5 * torchutils.sum_except_batch(\n",
    "            norm_inputs ** 2, num_batch_dims=1\n",
    "        )\n",
    "        log_prob -= torchutils.sum_except_batch(log_stds, num_batch_dims=1)\n",
    "        log_prob -= self._log_z\n",
    "        return log_prob\n",
    "\n",
    "    def _sample(self, num_samples, context):\n",
    "        means = self.mean_\n",
    "        log_stds = self.log_std_\n",
    "        stds = torch.exp(log_stds)\n",
    "        means = torchutils.repeat_rows(means, num_samples)\n",
    "        stds = torchutils.repeat_rows(stds, num_samples)\n",
    "\n",
    "        # Generate samples.\n",
    "        context_size = context.shape[0]\n",
    "        noise = torch.randn(context_size * num_samples, *\n",
    "                            self._shape, device=means.device)\n",
    "        samples = means + stds * noise\n",
    "        return torchutils.split_leading_dim(samples, [context_size, num_samples])\n",
    "\n",
    "    def _mean(self, context):\n",
    "        return self.mean\n",
    "\n",
    "def spline_inn(\n",
    "    inp_dim,\n",
    "    nodes=128,\n",
    "    num_blocks=2,\n",
    "    num_stack=3,\n",
    "    tail_bound=3.5,\n",
    "    tails=\"linear\",\n",
    "    activation=F.relu,\n",
    "    lu=0,\n",
    "    num_bins=10,\n",
    "    context_features=None,\n",
    "    dropout_probability=0.0,\n",
    "    flow_for_flow=False,\n",
    "):\n",
    "    transform_list = []\n",
    "    for i in range(num_stack):\n",
    "        transform_list += [\n",
    "            transforms.MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "                inp_dim,\n",
    "                nodes,\n",
    "                num_blocks=num_blocks,\n",
    "                tail_bound=tail_bound,\n",
    "                num_bins=num_bins,\n",
    "                tails=tails,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                context_features=context_features,\n",
    "            )\n",
    "        ]\n",
    "        if lu:\n",
    "            transform_list += [transforms.LULinear(inp_dim)]\n",
    "        else:\n",
    "            transform_list += [transforms.ReversePermutation(inp_dim)]\n",
    "\n",
    "    if not (flow_for_flow and (num_stack % 2 == 0)):\n",
    "        # If the above conditions are satisfied then you want to permute back to the original ordering such that the\n",
    "        # output features line up with their original ordering.\n",
    "        transform_list = transform_list[:-1]\n",
    "\n",
    "    return transforms.CompositeTransform(transform_list)\n",
    "\n",
    "def get_conditional_base_flow(\n",
    "    input_dim,\n",
    "    context_dim,\n",
    "    nstack,\n",
    "    nnodes,\n",
    "    nblocks,\n",
    "    tail_bound,\n",
    "    nbins,\n",
    "    activation,\n",
    "    dropout_probability,\n",
    "):\n",
    "    flow = Flow(\n",
    "        spline_inn(\n",
    "            input_dim,\n",
    "            nodes=nnodes,\n",
    "            num_blocks=nblocks,\n",
    "            num_stack=nstack,\n",
    "            tail_bound=tail_bound,\n",
    "            activation=getattr(F, activation),\n",
    "            dropout_probability=dropout_probability,\n",
    "            num_bins=nbins,\n",
    "            context_features=context_dim,\n",
    "        ),\n",
    "        #ConditionalDiagonalNormal(\n",
    "        #    shape=[input_dim], context_encoder=nn.Linear(context_dim, 2 * input_dim)\n",
    "        #),\n",
    "        DiagonalGaussian(shape=[input_dim], mean=0., std=0.25),\n",
    "    )\n",
    "\n",
    "    return flow\n",
    "\n",
    "def make_base_flow_and_train(loader, test_loader, df_test):\n",
    "    flow = get_conditional_base_flow(\n",
    "        input_dim=ninput,\n",
    "        context_dim=ncontext,\n",
    "        nstack=2,\n",
    "        nnodes=8,\n",
    "        nblocks=4,\n",
    "        tail_bound=1.0,\n",
    "        nbins=8,\n",
    "        activation=\"relu\",\n",
    "        dropout_probability=0.1,\n",
    "    )\n",
    "    flow = flow.to(device)\n",
    "    optimizer = optim.Adam(flow.parameters())\n",
    "\n",
    "    train_history, test_history = [], []\n",
    "    for epoch in range(epochs + 1):\n",
    "        print(epoch)\n",
    "        train_losses, test_losses = [], []\n",
    "\n",
    "        # train\n",
    "        for ab, xy, weights in loader:\n",
    "            loss = -flow.log_prob(inputs=xy, context=ab) * weights\n",
    "            loss = loss.mean()\n",
    "            train_losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_train_loss = np.mean(train_losses)\n",
    "        train_history.append(epoch_train_loss)\n",
    "\n",
    "        # test\n",
    "        print('testing')\n",
    "        for ab, xy, weights in test_loader:\n",
    "            with torch.no_grad():\n",
    "                loss = -flow.log_prob(inputs=xy, context=ab) * weights\n",
    "                loss = loss.mean()\n",
    "                test_losses.append(loss.item())\n",
    "        \n",
    "        epoch_test_loss = np.mean(test_losses)\n",
    "        test_history.append(epoch_test_loss)\n",
    "        if epoch % plot_every == 0:\n",
    "            print(\"plotting\")\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "            # Example data and function calls (ensure these are defined in your code)\n",
    "            a, b, x, y = df_test['a'].values, df_test['b'].values, df_test['x'].values, df_test['y'].values\n",
    "            xy_sample = flow.sample(1, context=torch.tensor(df_test[['a', 'b']].values, dtype=torch.float32).to(device)).reshape(-1, 2)\n",
    "            x_sample = xy_sample[:, 0].detach().cpu().numpy()\n",
    "            y_sample = xy_sample[:, 1].detach().cpu().numpy()\n",
    "\n",
    "            # Common limits for histograms\n",
    "            x_min, x_max = min(x.min(), x_sample.min()), max(x.max(), x_sample.max())\n",
    "            y_min, y_max = min(y.min(), y_sample.min()), max(y.max(), y_sample.max())\n",
    "\n",
    "            # Plotting histograms for x\n",
    "            ax1.hist(x, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label='sample')\n",
    "            ax1.hist(x_sample, bins=100, range=(x_min, x_max), density=True, alpha=0.5, color='red', label='flow')\n",
    "            ax1.legend(markerscale=50, loc=\"best\", fontsize=24)\n",
    "            ax1.tick_params(width=2, grid_alpha=0.5)\n",
    "            ax1.set_xlabel('X Values', fontsize=24)\n",
    "            ax1.text(0.13, 1.02, r'$\\mathbf{FUW}$ $\\mathit{Private}$', transform=ax1.transAxes, fontsize=12, ha='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='square'))\n",
    "\n",
    "            # Plotting histograms for y\n",
    "            ax2.hist(y, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label='sample')\n",
    "            ax2.hist(y_sample, bins=100, range=(y_min, y_max), density=True, alpha=0.5, color='red', label='flow')\n",
    "            ax2.legend(markerscale=50, loc=\"best\", fontsize=24)\n",
    "            ax2.tick_params(width=2, grid_alpha=0.5)\n",
    "            ax2.set_xlabel('Y Values', fontsize=24)\n",
    "            ax2.text(0.13, 1.02, r'$\\mathbf{FUW}$ $\\mathit{Private}$', transform=ax2.transAxes, fontsize=12, ha='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='square'))\n",
    "\n",
    "            # Plotting loss\n",
    "            ax3.plot(train_history, label='train')\n",
    "            ax3.plot(test_history, label='test')\n",
    "            ax3.legend(markerscale=50, loc=\"best\", fontsize=24)\n",
    "            ax3.tick_params(width=2, grid_alpha=0.5)\n",
    "            ax3.text(0.13, 1.02, r'$\\mathbf{FUW}$ $\\mathit{Private}$', transform=ax3.transAxes, fontsize=12, ha='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='square'))\n",
    "\n",
    "            # Adjust layout to not overlap content and save figures\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'For_epoch_{epoch}.pdf', bbox_inches='tight')\n",
    "            plt.savefig(f'For_epoch_{epoch}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()    \n",
    "        return flow\n",
    " \n",
    "\"\"\"\n",
    "        if epoch % plot_every == 0:\n",
    "            print(\"plotting\")\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "            a, b, x, y = df_test['a'].values, df_test['b'].values, df_test['x'].values, df_test['y'].values\n",
    "            xy_sample = flow.sample(1, context=torch.tensor(df_test[['a', 'b']].values, dtype=torch.float32).to(device)).reshape(-1, ninput)\n",
    "            x_sample = xy_sample[:, 0].detach().cpu().numpy()\n",
    "            y_sample = xy_sample[:, 1].detach().cpu().numpy()\n",
    "            x_min = min(x.min(), x_sample.min())\n",
    "            x_max = max(x.max(), x_sample.max())\n",
    "            ax1.hist(x, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label='sample');\n",
    "            ax1.hist(x_sample, bins=100, range=(x_min, x_max), density=True, alpha=0.5, label='flow');\n",
    "            y_min = min(y.min(), y_sample.min())\n",
    "            y_max = max(y.max(), y_sample.max())\n",
    "            ax1.legend()\n",
    "            ax2.hist(y, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label='sample');\n",
    "            ax2.hist(y_sample, bins=100, range=(y_min, y_max), density=True, alpha=0.5, label='flow');\n",
    "            ax2.legend()\n",
    "            # plot loss\n",
    "            ax3.plot(train_history, label='train')\n",
    "            ax3.plot(test_history, label='test')\n",
    "            ax3.legend()\n",
    "            plt.show()\n",
    "\"\"\"    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "testing\n",
      "plotting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow_mc = make_base_flow_and_train(mc_loader_train, mc_loader_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
